{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment1 -Baseline_Model-Feature_Extraction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fwkhan/CE888/blob/main/assignment1/Assignment1_Baseline_Model_Feature_Extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LOHA39JajpI"
      },
      "source": [
        "# Importing Zeugma for Glove word embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNS4t0r_KCud",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8335b1c3-510d-4f52-ad1b-81149ad364e3"
      },
      "source": [
        "!pip install zeugma"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting zeugma\n",
            "  Downloading https://files.pythonhosted.org/packages/59/38/8f57f83719027e36a61238abe1cafa55d257eaaf8e9185b2adbb5a928308/zeugma-0.48.tar.gz\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from zeugma) (1.19.5)\n",
            "Requirement already satisfied: Cython>=0.27.3 in /usr/local/lib/python3.7/dist-packages (from zeugma) (0.29.21)\n",
            "Requirement already satisfied: pandas>=0.20.3 in /usr/local/lib/python3.7/dist-packages (from zeugma) (1.1.5)\n",
            "Requirement already satisfied: gensim>=3.5.0 in /usr/local/lib/python3.7/dist-packages (from zeugma) (3.6.0)\n",
            "Requirement already satisfied: scikit_learn>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from zeugma) (0.22.2.post1)\n",
            "Requirement already satisfied: tensorflow>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from zeugma) (2.4.1)\n",
            "Requirement already satisfied: keras>=2.1.3 in /usr/local/lib/python3.7/dist-packages (from zeugma) (2.4.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.20.3->zeugma) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.20.3->zeugma) (2.8.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=3.5.0->zeugma) (1.4.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim>=3.5.0->zeugma) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=3.5.0->zeugma) (4.2.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit_learn>=0.19.1->zeugma) (1.0.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.5.0->zeugma) (3.12.4)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.5.0->zeugma) (1.12)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.5.0->zeugma) (1.1.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.5.0->zeugma) (0.10.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.5.0->zeugma) (0.36.2)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.5.0->zeugma) (1.12.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.5.0->zeugma) (2.4.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.5.0->zeugma) (0.3.3)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.5.0->zeugma) (1.32.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.5.0->zeugma) (3.7.4.3)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.5.0->zeugma) (3.3.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.5.0->zeugma) (1.6.3)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.5.0->zeugma) (2.10.0)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.5.0->zeugma) (2.4.1)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.5.0->zeugma) (1.1.2)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.5.0->zeugma) (0.2.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras>=2.1.3->zeugma) (3.13)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.9.2->tensorflow>=1.5.0->zeugma) (53.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=1.5.0->zeugma) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=1.5.0->zeugma) (1.8.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=1.5.0->zeugma) (1.27.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=1.5.0->zeugma) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=1.5.0->zeugma) (3.3.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=1.5.0->zeugma) (0.4.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=1.5.0->zeugma) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=1.5.0->zeugma) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=1.5.0->zeugma) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=1.5.0->zeugma) (2020.12.5)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=1.5.0->zeugma) (4.7.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=1.5.0->zeugma) (4.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=1.5.0->zeugma) (0.2.8)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow>=1.5.0->zeugma) (3.4.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=1.5.0->zeugma) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=1.5.0->zeugma) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow>=1.5.0->zeugma) (3.4.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=1.5.0->zeugma) (3.1.0)\n",
            "Building wheels for collected packages: zeugma\n",
            "  Building wheel for zeugma (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for zeugma: filename=zeugma-0.48-cp37-none-any.whl size=8778 sha256=ffe3b2d272720b2b19b299399f60a9475f20a683b06512ffac69bdf9e2ea99b2\n",
            "  Stored in directory: /root/.cache/pip/wheels/6a/b5/bc/5183ac478b0071d04d3ed0c0dd4a43db94c5c8ffb317b5eb53\n",
            "Successfully built zeugma\n",
            "Installing collected packages: zeugma\n",
            "Successfully installed zeugma-0.48\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2XZcgzRastY"
      },
      "source": [
        "# Downloading necessities for nltk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2snf_JzoqiLq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bc51987-974c-4d26-929b-9441abd89cf1"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('stopwords')\r\n",
        "nltk.download('wordnet')\r\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lk4JkCKPoEwY"
      },
      "source": [
        "# import torch\r\n",
        "# if torch.cuda.is_available():       \r\n",
        "#     device = torch.device(\"cuda\")\r\n",
        "#     print(f'There are {torch.cuda.device_count()} GPU(s) available.')\r\n",
        "#     print('Device name:', torch.cuda.get_device_name(0))\r\n",
        "\r\n",
        "# else:\r\n",
        "#     print('No GPU available, using the CPU instead.')\r\n",
        "#     device = torch.device(\"cpu\")\r\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6mFUIuoax-n"
      },
      "source": [
        "# Importing Necessities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPFoHm-Td2zu"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "# Marry nltk and ScikitLearn\r\n",
        "from nltk.classify.scikitlearn import SklearnClassifier\r\n",
        "from sklearn import feature_extraction, linear_model, model_selection, preprocessing\r\n",
        "import pickle\r\n",
        "from nltk import word_tokenize\r\n",
        "import nltk\r\n",
        "import random\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from nltk.classify import ClassifierI\r\n",
        "from statistics import mode\r\n",
        "from nltk.stem import PorterStemmer\r\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from nltk.stem import WordNetLemmatizer\r\n",
        "import seaborn as sns\r\n",
        "import requests\r\n",
        "\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuTogDJjQrH0"
      },
      "source": [
        "# Declaring URL link related to all the three datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lA-D50_uaK7f"
      },
      "source": [
        "############################ SENTIMENT ANALYSIS #################################################\r\n",
        "SENTIMENT_TRAIN_TEXT = 'https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/sentiment/train_text.txt'\r\n",
        "SENTIMENT_VALIDATION_TEXT = 'https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/sentiment/val_text.txt'\r\n",
        "SENTIMENT_TEST_TEXT = 'https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/sentiment/test_text.txt'\r\n",
        "\r\n",
        "SENTIMENT_TRAIN_LABEL = 'https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/sentiment/train_labels.txt'\r\n",
        "SENTIMENT_VALIDATION_LABEL = 'https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/sentiment/val_labels.txt'\r\n",
        "SENTIMENT_TEST_LABEL = 'https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/sentiment/test_labels.txt'\r\n",
        "\r\n",
        "############################ HATE #################################################\r\n",
        "HATE_TRAIN_TEXT = 'https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/hate/train_text.txt'\r\n",
        "HATE_VALIDATION_TEXT = 'https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/hate/val_text.txt'\r\n",
        "HATE_TEST_TEXT = 'https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/hate/test_text.txt'\r\n",
        "\r\n",
        "HATE_TRAIN_LABEL = 'https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/hate/train_labels.txt'\r\n",
        "HATE_VALIDATION_LABEL = 'https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/hate/val_labels.txt'\r\n",
        "HATE_TEST_LABEL = 'https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/hate/test_labels.txt'\r\n",
        "\r\n",
        "############################ OFFENSIVE LANGUAGE#################################################\r\n",
        "OFFENSE_TRAIN_TEXT = 'https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/offensive/train_text.txt'\r\n",
        "OFFENSE_VALIDATION_TEXT = 'https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/offensive/val_text.txt'\r\n",
        "OFFENSE_TEST_TEXT = 'https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/offensive/test_text.txt'\r\n",
        "\r\n",
        "OFFENSE_TRAIN_LABEL = 'https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/offensive/train_labels.txt'\r\n",
        "OFFENSE_VALIDATION_LABEL = 'https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/offensive/val_labels.txt'\r\n",
        "OFFENSE_TEST_LABEL = 'https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/offensive/test_labels.txt'\r\n",
        "\r\n",
        "############################ IRONY #################################################\r\n",
        "IRONY_TRAIN_TEXT = 'https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/irony/train_text.txt'\r\n",
        "IRONY_VALIDATION_TEXT = 'https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/irony/val_text.txt'\r\n",
        "IRONY_TEST_TEXT = 'https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/irony/test_text.txt'\r\n",
        "\r\n",
        "IRONY_TRAIN_LABEL = 'https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/irony/train_labels.txt'\r\n",
        "IRONY_VALIDATION_LABEL = 'https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/irony/val_labels.txt'\r\n",
        "IRONY_TEST_LABEL = 'https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/irony/test_labels.txt'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EevDzBIVQyvF"
      },
      "source": [
        "#In this part, text files are read from github, converted to pandsas dataframe and then processing is done to get rid of noise in the data. All the special characters are removed, words are lower-cased, lemmatization is done instead of stemming, all the words whose length is less than 2 are filtered, getting rid of 'user' from texts and calcualting the length of each tweet and storing it in dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5_F0_kzZz14"
      },
      "source": [
        "def preprocess(df): \n",
        "    lemmatizer  = WordNetLemmatizer()\n",
        "    \n",
        "    ps = PorterStemmer()\n",
        "    ignore_words = ['user', 'st'] \n",
        "    # Removing all the words not starting from alphabets A to Z(case insensitive)\n",
        "    df['processed_tweets'] = df['tweet'].replace('[^a-zA-Z]',' ', regex=True,\n",
        "                                                  inplace=False)\n",
        "    # Tokenizing and Converting to lower case.    \n",
        "    df['processed_tweets'] = df['processed_tweets'].apply(lambda x: [w.lower() for w in x.split()])\n",
        "    df['processed_tweets'] = df['processed_tweets'].apply(lambda tweet: ([word for word in tweet if not word in stopwords.words(\"english\")])) #only use stopwords with glove for max HATE accuracy\n",
        "    df['processed_tweets'] = df['processed_tweets'].apply(lambda tweet: ([lemmatizer.lemmatize(word) for word in tweet]))\n",
        "    df['processed_tweets'] = df['processed_tweets'].apply(lambda tweet: ([ps.stem(word) for word in tweet]))\n",
        " \n",
        "    df['processed_tweets'] = df['processed_tweets'].apply(lambda tweet: ' '.join([word for word in tweet if len(word)>2]))\n",
        "    df['processed_tweets'] = df['processed_tweets'].apply(lambda x: ' '.join([word for word in x.split() if not word in ignore_words]))\n",
        "\n",
        "    # Calculate sentence length for each tweet and store it in data frame\n",
        "    df[\"sentence_length\"] = df.tweet.apply(lambda x: len(str(x).split()))\n",
        "    return df\n",
        " \n",
        " \n",
        "# Wrapper to convert text data to pandas Dataframe\n",
        "def txt_to_df(data, label, classification_task):\n",
        "    tweet = []\n",
        "    sentiments = []\n",
        "    # Split the input string by new line and store in tweet list\n",
        "    for sentence in data.split('\\n'):\n",
        "        tweet.append(sentence)\n",
        "    # Split labels by new line and store it in sentiments list\n",
        "    for sentiment in label.split('\\n'):\n",
        "        # Exception handling is done since the last line is is empty in th\n",
        "        # original text file and we get system error as we try to cast to int.      \n",
        "        try:\n",
        "            sentiments.append(int(sentiment))\n",
        "        except ValueError:\n",
        "            pass\n",
        "    # converting list to dataframe and removing the last blank line\n",
        "    df= pd.DataFrame(tweet[:-1], columns=['tweet'])\n",
        "    df['label'] = sentiments\n",
        "    # Converting labels to corresponding string based on the task type.\n",
        "    if classification_task == 'Sentiment_analysis':\n",
        "      df['sentiment'] = df.label.apply(lambda x: 'Negative'if x==0 else ('Neutral' if x==1 else 'Positive'))\n",
        "    if classification_task == 'hate_analysis':\n",
        "      df['sentiment'] = df.label.apply(lambda x: 'Not-hate'if x==0 else 'hate')\n",
        "    if classification_task == 'offensive_analysis':\n",
        "      df['sentiment'] = df.label.apply(lambda x: 'Not-offensive 'if x==0 else 'offensive')\n",
        "    if classification_task == 'irony_analysis':\n",
        "      df['sentiment'] = df.label.apply(lambda x: 'Non-irony 'if x==0 else 'irony')      \n",
        "    return df\n",
        " \n",
        " \n",
        "def prepare_dataset(TRAIN_TEXT, TRAIN_LABEL, VAL_TEXT, VAL_LABEL, TEST_TEXT, TEST_LABEL, classification_task):\n",
        "  # Reading Train, Vvalidation & Test data from tweeteval Github Repo.\n",
        "  train_tweets_txt = requests.get(TRAIN_TEXT).text\n",
        "  train_labels_txt = requests.get(TRAIN_LABEL).text\n",
        " \n",
        "  val_tweets_txt = requests.get(VAL_TEXT).text\n",
        "  val_labels_txt = requests.get(VAL_LABEL).text\n",
        " \n",
        "  test_tweets_txt = requests.get(TEST_TEXT).text\n",
        "  test_labels_txt = requests.get(TEST_LABEL).text\n",
        " \n",
        "  # Converting text data to pandas Dataframe\n",
        "  train_df = txt_to_df(train_tweets_txt, train_labels_txt, classification_task)\n",
        "  val_df = txt_to_df(val_tweets_txt, val_labels_txt, classification_task)\n",
        "  test_df = txt_to_df(test_tweets_txt, test_labels_txt, classification_task)\n",
        " \n",
        "  train_df = preprocess(train_df)\n",
        "  val_df = preprocess(val_df)\n",
        "  test_df = preprocess(test_df)  \n",
        " \n",
        "  return train_df, val_df, test_df"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TA2OA-k5_ye"
      },
      "source": [
        "#Random OverSampling\r\n",
        "EDA shows class imbalance, we randomly oversample the samples of minority class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xzJ-qQ15-Ii"
      },
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\r\n",
        "\r\n",
        "def smot_oversmapling(X, y):\r\n",
        "  X = X.reshape(-1,1)\r\n",
        "  oversample = RandomOverSampler()\r\n",
        "\r\n",
        "  X_train_smot, y_train_smot = oversample.fit_resample(X, y)\r\n",
        "  X_train_smot = X_train_smot.reshape(len(X_train_smot),)\r\n",
        "  # print('Shape of Training and Labelled data after random oversampling:', X_train_smot.shape, y_train_smot.shape)\r\n",
        "  return X_train_smot, y_train_smot"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcdoA_OrqRO9"
      },
      "source": [
        "# Feature Extraction\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kuz4uEaBdAYR"
      },
      "source": [
        "Wrapper API to print the shame training data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ic_ZeMddBFaf"
      },
      "source": [
        "def print_embedding_shape(X_train, y_train, X_val, y_val, X_test, y_test):\r\n",
        "  print('Shape of Training and Labelled data after random oversampling:', X_train.shape, y_train.shape)\r\n",
        "  # print('Shape of Validation and Labelled data after random oversampling:', X_val.shape, y_val.shape)\r\n",
        "  # print('Shape of Test and Labelled data after random oversampling:', X_test.shape, y_test.shape)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F630YlTXPF7H"
      },
      "source": [
        "##Word Embedding\r\n",
        "---Tranforming Text to Vectors\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9Y3PWLf_Nea"
      },
      "source": [
        "###Count Vectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dbn9VMjCEilt"
      },
      "source": [
        "#### Total features\r\n",
        "\r\n",
        "*   n-gram - 37221\r\n",
        "*   bi-grams - 328966\r\n",
        "*   tri-grams - 682076\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nV3HhQe40Ky7"
      },
      "source": [
        "# Wrapper Function for Count Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Twuq7y9SqRO9"
      },
      "source": [
        "# Transformin Dataset into a vector on the basis of the frequency (count) of each word that occurs in the entire text.\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "\r\n",
        "def embedding_count_vectorize(X_train, y_train, X_val, y_val, X_test, y_test, ngram=1):\r\n",
        "  # Create Vector object\r\n",
        "  countvector=CountVectorizer(ngram_range=(1,ngram)) # max_features = default, ngrams_range=(1,1)\r\n",
        "\r\n",
        "  # Fit and Transform Train data\r\n",
        "  X_train=countvector.fit_transform(X_train)\r\n",
        "\r\n",
        "  # Printing the identified Unique words along with trigrams \r\n",
        "  vocab_dict = countvector.vocabulary_\r\n",
        "  # print('Sample Vocabulary',{k: vocab_dict[k] for k in list(vocab_dict)[:20]})\r\n",
        "\r\n",
        "  # Summarizing the Encoded Texts \r\n",
        "  # print(\"Encoded Document is:\") \r\n",
        "  # print(countvector.toarray())\r\n",
        "\r\n",
        "  # Transform Validation dataset\r\n",
        "  X_val = countvector.transform(val_df['processed_tweets'])\r\n",
        "  y_val = val_df.label\r\n",
        "\r\n",
        "  # Transform Test dataset\r\n",
        "  X_test = countvector.transform(test_df['processed_tweets'])\r\n",
        "  y_test = test_df.label\r\n",
        "\r\n",
        "  print_embedding_shape(X_train, y_train, X_val, y_val, X_test, y_test)\r\n",
        "  return X_train, y_train, X_val, y_val, X_test, y_test"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQxf8PE70Pg2"
      },
      "source": [
        "# Wrapper Function for TF-IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23Jc40uoPWw-"
      },
      "source": [
        "###TF-IDF\r\n",
        "\r\n",
        "#### Total features\r\n",
        "\r\n",
        "*   n-gram - 37221\r\n",
        "*   bi-grams - 328966\r\n",
        "*   tri-grams - 682076\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRFIWEPg6ZAc"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "\r\n",
        "def embedding_tfidf(X_train, y_train, X_val, y_val, X_test, y_test, ngram=1):\r\n",
        "\r\n",
        "  tokenization = TfidfVectorizer(ngram_range=(1,ngram))\r\n",
        "  X_train = tokenization.fit_transform(X_train)\r\n",
        "\r\n",
        "  X_val = tokenization.transform(val_df['processed_tweets'])\r\n",
        "  y_val = val_df.label\r\n",
        "\r\n",
        "  # Transform Test dataset\r\n",
        "  X_test = tokenization.transform(test_df['processed_tweets'])\r\n",
        "  y_test = test_df.label\r\n",
        "  print_embedding_shape(X_train, y_train, X_val, y_val, X_test, y_test)\r\n",
        "  return X_train, y_train, X_val, y_val, X_test, y_test"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qCqay9h0gb4"
      },
      "source": [
        "# Wrapper Function for Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aweC_8ytkHl"
      },
      "source": [
        "from gensim.models import Word2Vec\r\n",
        "w2v_model = 0 \r\n",
        "def embedding_Word2Vec(X_train, y_train, X_val, y_val, X_test, y_test):\r\n",
        "\r\n",
        "  X_train = pd.DataFrame(X_train, columns=['tweet'])\r\n",
        "  X_train['tokend'] = X_train['tweet'].apply(word_tokenize)\r\n",
        "\r\n",
        "  X_val = pd.DataFrame(X_val, columns=['tweet'])\r\n",
        "  X_val['tokend'] = X_val['tweet'].apply(word_tokenize)\r\n",
        "\r\n",
        "  X_test = pd.DataFrame(X_test, columns=['tweet'])\r\n",
        "  X_test['tokend'] = X_test['tweet'].apply(word_tokenize)\r\n",
        "\r\n",
        "\r\n",
        "  # w2v = Word2Vec(X_train.tokend, size=350, window=10, min_count=1, iter=20)\r\n",
        "\r\n",
        "  def text_to_vector(text):\r\n",
        "      \"\"\"Create document vectors by averaging word vectors. Remove out-of-vocabulary words.\"\"\"\r\n",
        "      text = [word for word in text if word in w2v_model.wv.vocab]\r\n",
        "      if not len(text):\r\n",
        "        text = ['tweet']\r\n",
        "      return np.mean(w2v_model[text], axis=0)\r\n",
        "\r\n",
        "\r\n",
        "  w2v_model = Word2Vec(X_train.tokend, min_count=20,\r\n",
        "                      window=7,\r\n",
        "                      size=300,\r\n",
        "                      sample=6e-5, \r\n",
        "                      alpha=0.03, \r\n",
        "                      min_alpha=0.0007, \r\n",
        "                      negative=10)\r\n",
        "\r\n",
        "  X_train['doc_vector'] = X_train['tokend'].apply(text_to_vector)\r\n",
        "  X_val['doc_vector'] = X_val['tokend'].apply(text_to_vector)\r\n",
        "  X_test['doc_vector'] = X_test['tokend'].apply(text_to_vector)\r\n",
        "\r\n",
        "  y_train = y_train\r\n",
        "  y_test = y_test\r\n",
        "  y_val = y_val\r\n",
        "\r\n",
        "  x_train = list(X_train['doc_vector'])\r\n",
        "  x_val = list(X_val['doc_vector'])\r\n",
        "  x_test = list(X_test['doc_vector'])\r\n",
        "  train_model(x_train, y_train, x_val, y_val, x_test, y_test)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1OLku8v66ho"
      },
      "source": [
        "# Wrapper Function for Glove Word Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuInbXvB3Jsb"
      },
      "source": [
        "from zeugma.embeddings import EmbeddingTransformer\r\n",
        "\r\n",
        "def embedding_Glove(X_train, y_train, X_val, y_val, X_test, y_test):\r\n",
        "    glove = EmbeddingTransformer('glove')\r\n",
        "    x_train = glove.transform(X_train)\r\n",
        "    x_val = glove.transform(X_val)\r\n",
        "    x_test = glove.transform(X_test)\r\n",
        "    \r\n",
        "    train_model(x_train, y_train, x_val, y_val, x_test, y_test)\r\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTRIb9ZvkY2F"
      },
      "source": [
        "#Returns the dataframe of all three Datasets "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQAH8J7Di2Qp"
      },
      "source": [
        "def get_dataset():\r\n",
        "  X = train_df.processed_tweets.values\r\n",
        "  y = train_df.label.values\r\n",
        "\r\n",
        "  X_train, y_train = smot_oversmapling(X, y)\r\n",
        "\r\n",
        "  X_val = val_df.processed_tweets.values\r\n",
        "  y_val = val_df.label.values\r\n",
        "\r\n",
        "  X_test = test_df.processed_tweets.values\r\n",
        "  y_test = test_df.label.values\r\n",
        "  return X_train, y_train, X_val, y_val, X_test, y_test"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rc1Q8nTqRO-"
      },
      "source": [
        "# Classification\r\n",
        "Logistic Regression as baseline classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wHMIn8PlnWU"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.svm import LinearSVC\r\n",
        "def logistic_classifier(X_train, y_train):\r\n",
        "  \"\"\" \r\n",
        "    Initialize LogisticRegression Object. \r\n",
        "\r\n",
        "    Parameters: \r\n",
        "    X_train (DataFrame): Input Training Data set  \r\n",
        "    y_train (DataFrame): Labelled Training Data \r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    Returns: \r\n",
        "    model: Object LogisticRegression \r\n",
        "\r\n",
        "  \"\"\"    \r\n",
        "  model = LogisticRegression(max_iter=100)\r\n",
        "  # model = LinearSVC(C=0.5, random_state=70, max_iter=2000)\r\n",
        "\r\n",
        "  return model"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOkRTggt7iw2"
      },
      "source": [
        "# Wrapper function to perform training and evaluation\r\n",
        "Performance Metric: Recall for sentiment analysis and F1 for the other two."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIpUyBjmmcXH"
      },
      "source": [
        "from sklearn.metrics import recall_score, f1_score\r\n",
        "\r\n",
        "def fit_models(classifier, X_train, y_train, X_val, y_val, X_test, y_test):\r\n",
        "    \"\"\" \r\n",
        "      Wrapper to train and Validate Classifiers. \r\n",
        "\r\n",
        "      This is a wrapper function which trains the classifer, gets the test \r\n",
        "      score, performs k-fold cross validation with 10 splits.\r\n",
        "\r\n",
        "      Parameters: \r\n",
        "      X_train (DataFrame): Input Training Data set  \r\n",
        "      y_train (DataFrame): Labelled Training Data \r\n",
        "      X_test (DataFrame): Input Validation Data set\r\n",
        "      y_test (DataFrame): Labelled Validation Data\r\n",
        "\r\n",
        "      Returns: \r\n",
        "      Validation Score: Gives default score, f1 score and recall score\r\n",
        "      Test Score: Gives default score, f1 score and recall score\r\n",
        "\r\n",
        "    \"\"\"     \r\n",
        "    classifier.fit(X_train, y_train)\r\n",
        "\r\n",
        "    validation_score = classifier.score(X_val,y_val)\r\n",
        "    test_score = classifier.score(X_test,y_test)\r\n",
        "\r\n",
        "    y_val_pred = classifier.predict(X_val)\r\n",
        "    recallScore_val = recall_score(y_val, y_val_pred, average='macro')\r\n",
        "    f1Score_val = f1_score(y_val, y_val_pred, average='macro')\r\n",
        "\r\n",
        "    y_test_pred = classifier.predict(X_test)\r\n",
        "\r\n",
        "    # Performance Metric: Recall for sentiment analysis and F1 for the other two.\r\n",
        "    recallScore_test = recall_score(y_test, y_test_pred, average='macro')\r\n",
        "    f1Score_test = f1_score(y_test, y_test_pred, average='macro')\r\n",
        "\r\n",
        "\r\n",
        "    return validation_score, recallScore_val, test_score, recallScore_test, f1Score_val, f1Score_test"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10UyhaiJ8jDd"
      },
      "source": [
        "# Wrapper function to initiate training of baseline classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQyhYqNpeCsi"
      },
      "source": [
        "def train_model(X_train, y_train, X_val, y_val, X_test, y_test):\r\n",
        "  classifier_lr = logistic_classifier(X_train, y_train)\r\n",
        "  validation_score, recallScore_val, test_score, recallScore_test, f1Score_val, f1Score_test = fit_models(classifier_lr, X_train, y_train, X_val, y_val, X_test, y_test)\r\n",
        "  print('Validation Score: {}\\nTest Score: {}'\r\n",
        "    .format(validation_score,test_score)) \r\n",
        "  print('Validation Recall Score: {}\\nTest Recall Score: {}'\r\n",
        "    .format(recallScore_val, recallScore_test)) \r\n",
        "  print('Validation F1 Score: {}\\nTest F1 Score: {}'\r\n",
        "    .format(f1Score_val, f1Score_test)) "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJb-QVMmnD3N"
      },
      "source": [
        "# Wrapper to train for baseline classifier with combination of N-gram with Count Vectorizer word embedding.\r\n",
        "Training is done for N-gram 1,2&3 with count vectorizer and baseline model is trained and evaluated"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVn0BS3tpSuY"
      },
      "source": [
        "def embedding_count_vectorize_ngram(X_train, y_train, X_val, y_val, X_test, y_test):\r\n",
        "  for ngram in range(1,4):\r\n",
        "    print('N-GRAM: {}'.format(ngram))\r\n",
        "    X_train, y_train, X_val, y_val, X_test, y_test = get_dataset()\r\n",
        "    X_train, y_train, X_val, y_val, X_test, y_test = embedding_count_vectorize(X_train, y_train, X_val, y_val, X_test, y_test, ngram)\r\n",
        "    train_model(X_train, y_train, X_val, y_val, X_test, y_test)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqGmp_jJ9M3Q"
      },
      "source": [
        "# Wrapper to train for baseline classifier with combination of N-gram with TF-IDF word embedding.\r\n",
        "Training is done for N-gram 1,2&3 with TF-IDF and baseline model is trained and evaluated"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8x-fOzbqq8H"
      },
      "source": [
        "def embedding_tfid_ngram(X_train, y_train, X_val, y_val, X_test, y_test):\r\n",
        "  for ngram in range(1,4):\r\n",
        "    print('N-GRAM: {}'.format(ngram))\r\n",
        "    X_train, y_train, X_val, y_val, X_test, y_test = get_dataset()\r\n",
        "    X_train, y_train, X_val, y_val, X_test, y_test = embedding_tfidf(X_train, y_train, X_val, y_val, X_test, y_test, ngram)\r\n",
        "    train_model(X_train, y_train, X_val, y_val, X_test, y_test)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNcByDE99fvG"
      },
      "source": [
        "# Wrapper to init training\r\n",
        "'features_extraction' - Name of the embedding function \r\n",
        "Example: embedding_tfidf_ngram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-M4u1vrnCNn"
      },
      "source": [
        "def init_training(features_extraction):\r\n",
        "  X_train, y_train, X_val, y_val, X_test, y_test = get_dataset()\r\n",
        "  feature_extraction(X_train, y_train, X_val, y_val, X_test, y_test)\r\n",
        "  # train_model(X_train, y_train, X_val, y_val, X_test, y_test)  "
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ob-0LBiR9_sR"
      },
      "source": [
        "# Starting point of the script:\r\n",
        "We declare classification task dictionary, over which we iterate for all the three tasks.\r\n",
        "\r\n",
        "We, also declare class dictionary, which containes all the classes specific to a given task as values.\r\n",
        "\r\n",
        "For every Classification Task, we loop over all the feature extraction methods, train Logistic Regression classifer and evaluate performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "653owJmLuxGn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "626b6bfd-0b06-4f3b-ddb1-ff83d9c870f7"
      },
      "source": [
        "import warnings\r\n",
        "warnings.filterwarnings('ignore')\r\n",
        "# List of all the feature extraction method function names\r\n",
        "feature_extraction_strategy = [embedding_tfid_ngram, embedding_count_vectorize_ngram, embedding_Glove, embedding_Word2Vec]\r\n",
        "\r\n",
        "# class dictionary, which containes all the classes specific to a given task as values                       \r\n",
        "classification_task = {'SENTIMENT_ANALYSIS' : 'Sentiment_analysis',\r\n",
        "                       'HATE_ANALYSIS' : 'hate_analysis',\r\n",
        "                       'OFFENSIVE_LANGUAGE' : 'offensive_analysis',\r\n",
        "                       'IRONY_ANALYSIS' : 'irony_analysis'\r\n",
        "                       }\r\n",
        "# Loop over all three classification tasks(sentiment analysis, hate word, offensive language) and perform training and evaluation\r\n",
        "for key, task in classification_task.items():\r\n",
        "  print('=========================================')\r\n",
        "  print('CLASSIFICATION TASK: {}'.format(key))\r\n",
        "  print('=========================================')\r\n",
        "  if key == 'SENTIMENT_ANALYSIS':\r\n",
        "    train_df, val_df, test_df = prepare_dataset(SENTIMENT_TRAIN_TEXT, SENTIMENT_TRAIN_LABEL,\r\n",
        "                        SENTIMENT_VALIDATION_TEXT, SENTIMENT_VALIDATION_LABEL,\r\n",
        "                        SENTIMENT_TEST_TEXT, SENTIMENT_TEST_LABEL, classification_task['SENTIMENT_ANALYSIS']\r\n",
        "                        )\r\n",
        "  if key == 'HATE_ANALYSIS':\r\n",
        "    train_df, val_df, test_df = prepare_dataset(HATE_TRAIN_TEXT, HATE_TRAIN_LABEL,\r\n",
        "                        HATE_VALIDATION_TEXT, HATE_VALIDATION_LABEL,\r\n",
        "                        HATE_TEST_TEXT, HATE_TEST_LABEL, classification_task['HATE_ANALYSIS']\r\n",
        "                        )\r\n",
        "  if key == 'OFFENSIVE_LANGUAGE':\r\n",
        "    train_df, val_df, test_df = prepare_dataset(OFFENSE_TRAIN_TEXT, OFFENSE_TRAIN_LABEL,\r\n",
        "                        OFFENSE_VALIDATION_TEXT, OFFENSE_VALIDATION_LABEL,\r\n",
        "                        OFFENSE_TEST_TEXT, OFFENSE_TEST_LABEL, classification_task['OFFENSIVE_LANGUAGE']\r\n",
        "                        )\r\n",
        "  if key == 'IRONY_ANALYSIS':\r\n",
        "    continue\r\n",
        "    train_df, val_df, test_df = prepare_dataset(OFFENSE_TRAIN_TEXT, OFFENSE_TRAIN_LABEL,\r\n",
        "                        OFFENSE_VALIDATION_TEXT, OFFENSE_VALIDATION_LABEL,\r\n",
        "                        OFFENSE_TEST_TEXT, OFFENSE_TEST_LABEL, classification_task['IRONY_ANALYSIS']\r\n",
        "                        )    \r\n",
        "  for feature_extraction in feature_extraction_strategy:\r\n",
        "    print('FEATURE EXTRACTION STRATEGY TASK: {}'.format(feature_extraction))\r\n",
        "    init_training(feature_extraction)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=========================================\n",
            "CLASSIFICATION TASK: SENTIMENT_ANALYSIS\n",
            "=========================================\n",
            "FEATURE EXTRACTION STRATEGY TASK: <function embedding_tfid_ngram at 0x7fd44a5f40e0>\n",
            "N-GRAM: 1\n",
            "Shape of Training and Labelled data after random oversampling: (62019, 31785) (62019,)\n",
            "Validation Score: 0.6395\n",
            "Test Score: 0.5845815695213286\n",
            "Validation Recall Score: 0.6375318891141676\n",
            "Test Recall Score: 0.5854045025282203\n",
            "Validation F1 Score: 0.6191237583673089\n",
            "Test F1 Score: 0.5776572641499244\n",
            "N-GRAM: 2\n",
            "Shape of Training and Labelled data after random oversampling: (62019, 311980) (62019,)\n",
            "Validation Score: 0.654\n",
            "Test Score: 0.5919895799413871\n",
            "Validation Recall Score: 0.6528525389284884\n",
            "Test Recall Score: 0.5997904016983543\n",
            "Validation F1 Score: 0.634165153846128\n",
            "Test F1 Score: 0.5868767127560753\n",
            "N-GRAM: 3\n",
            "Shape of Training and Labelled data after random oversampling: (62019, 659830) (62019,)\n",
            "Validation Score: 0.641\n",
            "Test Score: 0.5857212634321068\n",
            "Validation Recall Score: 0.6437749428255758\n",
            "Test Recall Score: 0.6010914451388882\n",
            "Validation F1 Score: 0.6195654419282443\n",
            "Test F1 Score: 0.5823711314058166\n",
            "FEATURE EXTRACTION STRATEGY TASK: <function embedding_count_vectorize_ngram at 0x7fd416bbdc20>\n",
            "N-GRAM: 1\n",
            "Shape of Training and Labelled data after random oversampling: (62019, 31785) (62019,)\n",
            "Validation Score: 0.6435\n",
            "Test Score: 0.5701725822207749\n",
            "Validation Recall Score: 0.6337057808576796\n",
            "Test Recall Score: 0.5701488270610959\n",
            "Validation F1 Score: 0.6228860449282618\n",
            "Test F1 Score: 0.5612452670529314\n",
            "N-GRAM: 2\n",
            "Shape of Training and Labelled data after random oversampling: (62019, 311980) (62019,)\n",
            "Validation Score: 0.667\n",
            "Test Score: 0.6055845001628134\n",
            "Validation Recall Score: 0.6319454104264232\n",
            "Test Recall Score: 0.5838593031998437\n",
            "Validation F1 Score: 0.6379632082529484\n",
            "Test F1 Score: 0.587132742693062\n",
            "N-GRAM: 3\n",
            "Shape of Training and Labelled data after random oversampling: (62019, 659830) (62019,)\n",
            "Validation Score: 0.6765\n",
            "Test Score: 0.60786388798437\n",
            "Validation Recall Score: 0.6338722224798174\n",
            "Test Recall Score: 0.5754569103928201\n",
            "Validation F1 Score: 0.6454533360316711\n",
            "Test F1 Score: 0.5819445772067032\n",
            "FEATURE EXTRACTION STRATEGY TASK: <function embedding_Glove at 0x7fd447caaf80>\n",
            "[==================================================] 100.0% 104.8/104.8MB downloaded\n",
            "Validation Score: 0.5135\n",
            "Test Score: 0.5210843373493976\n",
            "Validation Recall Score: 0.5407690059588793\n",
            "Test Recall Score: 0.5401672421113196\n",
            "Validation F1 Score: 0.5001271905857245\n",
            "Test F1 Score: 0.5111367012180671\n",
            "FEATURE EXTRACTION STRATEGY TASK: <function embedding_Word2Vec at 0x7fd44a14e320>\n",
            "Validation Score: 0.4585\n",
            "Test Score: 0.4710192119830674\n",
            "Validation Recall Score: 0.4739046115628394\n",
            "Test Recall Score: 0.47775496819893276\n",
            "Validation F1 Score: 0.44252950701888105\n",
            "Test F1 Score: 0.45502548575221563\n",
            "=========================================\n",
            "CLASSIFICATION TASK: HATE_ANALYSIS\n",
            "=========================================\n",
            "FEATURE EXTRACTION STRATEGY TASK: <function embedding_tfid_ngram at 0x7fd44a5f40e0>\n",
            "N-GRAM: 1\n",
            "Shape of Training and Labelled data after random oversampling: (10434, 11834) (10434,)\n",
            "Validation Score: 0.708\n",
            "Test Score: 0.4845117845117845\n",
            "Validation Recall Score: 0.7061155592612121\n",
            "Test Recall Score: 0.547599277709797\n",
            "Validation F1 Score: 0.7040172561994194\n",
            "Test F1 Score: 0.42726193728595874\n",
            "N-GRAM: 2\n",
            "Shape of Training and Labelled data after random oversampling: (10434, 83376) (10434,)\n",
            "Validation Score: 0.706\n",
            "Test Score: 0.4616161616161616\n",
            "Validation Recall Score: 0.7151113127424173\n",
            "Test Recall Score: 0.529542022635727\n",
            "Validation F1 Score: 0.705480467544749\n",
            "Test F1 Score: 0.38653952997263147\n",
            "N-GRAM: 3\n",
            "Shape of Training and Labelled data after random oversampling: (10434, 162505) (10434,)\n",
            "Validation Score: 0.708\n",
            "Test Score: 0.4498316498316498\n",
            "Validation Recall Score: 0.7222269905301405\n",
            "Test Recall Score: 0.5192474346052137\n",
            "Validation F1 Score: 0.7079813108038913\n",
            "Test F1 Score: 0.36741923189023157\n",
            "FEATURE EXTRACTION STRATEGY TASK: <function embedding_count_vectorize_ngram at 0x7fd416bbdc20>\n",
            "N-GRAM: 1\n",
            "Shape of Training and Labelled data after random oversampling: (10434, 11834) (10434,)\n",
            "Validation Score: 0.693\n",
            "Test Score: 0.4946127946127946\n",
            "Validation Recall Score: 0.6903413154807885\n",
            "Test Recall Score: 0.5537305619507042\n",
            "Validation F1 Score: 0.6885901247566795\n",
            "Test F1 Score: 0.4482422908421342\n",
            "N-GRAM: 2\n",
            "Shape of Training and Labelled data after random oversampling: (10434, 83376) (10434,)\n",
            "Validation Score: 0.722\n",
            "Test Score: 0.49158249158249157\n",
            "Validation Recall Score: 0.7201221231776549\n",
            "Test Recall Score: 0.5500279878155371\n",
            "Validation F1 Score: 0.7180744689050338\n",
            "Test F1 Score: 0.4462239454707103\n",
            "N-GRAM: 3\n",
            "Shape of Training and Labelled data after random oversampling: (10434, 162505) (10434,)\n",
            "Validation Score: 0.724\n",
            "Test Score: 0.48484848484848486\n",
            "Validation Recall Score: 0.7206738845224812\n",
            "Test Recall Score: 0.5437739663104806\n",
            "Validation F1 Score: 0.7194026937341401\n",
            "Test F1 Score: 0.4374621186611893\n",
            "FEATURE EXTRACTION STRATEGY TASK: <function embedding_Glove at 0x7fd447caaf80>\n",
            "Validation Score: 0.627\n",
            "Test Score: 0.5104377104377105\n",
            "Validation Recall Score: 0.6196218595583457\n",
            "Test Recall Score: 0.5366449768844819\n",
            "Validation F1 Score: 0.6194339666917996\n",
            "Test F1 Score: 0.5070558550858044\n",
            "FEATURE EXTRACTION STRATEGY TASK: <function embedding_Word2Vec at 0x7fd44a14e320>\n",
            "Validation Score: 0.573\n",
            "Test Score: 0.4750841750841751\n",
            "Validation Recall Score: 0.5656391644289679\n",
            "Test Recall Score: 0.49547034407346385\n",
            "Validation F1 Score: 0.5653107824304116\n",
            "Test F1 Score: 0.47365058614564837\n",
            "=========================================\n",
            "CLASSIFICATION TASK: OFFENSIVE_LANGUAGE\n",
            "=========================================\n",
            "FEATURE EXTRACTION STRATEGY TASK: <function embedding_tfid_ngram at 0x7fd44a5f40e0>\n",
            "N-GRAM: 1\n",
            "Shape of Training and Labelled data after random oversampling: (15950, 12342) (15950,)\n",
            "Validation Score: 0.743202416918429\n",
            "Test Score: 0.7813953488372093\n",
            "Validation Recall Score: 0.7155263389877466\n",
            "Test Recall Score: 0.7181451612903226\n",
            "Validation F1 Score: 0.7159651606813403\n",
            "Test F1 Score: 0.7225730287722381\n",
            "N-GRAM: 2\n",
            "Shape of Training and Labelled data after random oversampling: (15950, 96642) (15950,)\n",
            "Validation Score: 0.729607250755287\n",
            "Test Score: 0.7697674418604651\n",
            "Validation Recall Score: 0.7040991348369792\n",
            "Test Recall Score: 0.7113575268817205\n",
            "Validation F1 Score: 0.7030423015236569\n",
            "Test F1 Score: 0.7124348131535574\n",
            "N-GRAM: 3\n",
            "Shape of Training and Labelled data after random oversampling: (15950, 187005) (15950,)\n",
            "Validation Score: 0.7265861027190332\n",
            "Test Score: 0.7744186046511627\n",
            "Validation Recall Score: 0.7028095759819664\n",
            "Test Recall Score: 0.7145833333333333\n",
            "Validation F1 Score: 0.7008996325585111\n",
            "Test F1 Score: 0.7167671664493698\n",
            "FEATURE EXTRACTION STRATEGY TASK: <function embedding_count_vectorize_ngram at 0x7fd416bbdc20>\n",
            "N-GRAM: 1\n",
            "Shape of Training and Labelled data after random oversampling: (15950, 12342) (15950,)\n",
            "Validation Score: 0.7462235649546828\n",
            "Test Score: 0.7779069767441861\n",
            "Validation Recall Score: 0.7132368682861713\n",
            "Test Recall Score: 0.7131720430107527\n",
            "Validation F1 Score: 0.7159872110483468\n",
            "Test F1 Score: 0.7177619585182589\n",
            "N-GRAM: 2\n",
            "Shape of Training and Labelled data after random oversampling: (15950, 96642) (15950,)\n",
            "Validation Score: 0.7575528700906344\n",
            "Test Score: 0.8034883720930233\n",
            "Validation Recall Score: 0.7086138501643432\n",
            "Test Recall Score: 0.7168682795698925\n",
            "Validation F1 Score: 0.7174128559317807\n",
            "Test F1 Score: 0.7333793171766165\n",
            "N-GRAM: 3\n",
            "Shape of Training and Labelled data after random oversampling: (15950, 187005) (15950,)\n",
            "Validation Score: 0.763595166163142\n",
            "Test Score: 0.8127906976744186\n",
            "Validation Recall Score: 0.708125228254436\n",
            "Test Recall Score: 0.7182123655913979\n",
            "Validation F1 Score: 0.7190897524278985\n",
            "Test F1 Score: 0.7391243728226609\n",
            "FEATURE EXTRACTION STRATEGY TASK: <function embedding_Glove at 0x7fd447caaf80>\n",
            "Validation Score: 0.6669184290030211\n",
            "Test Score: 0.7290697674418605\n",
            "Validation Recall Score: 0.6663480549573715\n",
            "Test Recall Score: 0.688239247311828\n",
            "Validation F1 Score: 0.652128425860334\n",
            "Test F1 Score: 0.6785273672068395\n",
            "FEATURE EXTRACTION STRATEGY TASK: <function embedding_Word2Vec at 0x7fd44a14e320>\n",
            "Validation Score: 0.5483383685800605\n",
            "Test Score: 0.5511627906976744\n",
            "Validation Recall Score: 0.517309557091944\n",
            "Test Recall Score: 0.5176075268817204\n",
            "Validation F1 Score: 0.5156413644594529\n",
            "Test F1 Score: 0.5052432648340577\n",
            "=========================================\n",
            "CLASSIFICATION TASK: IRONY_ANALYSIS\n",
            "=========================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3xGQfAGPTnf"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    }
  ]
}