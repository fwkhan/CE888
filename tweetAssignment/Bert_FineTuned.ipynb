{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bert_FineTuned.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fwkhan/CE888/blob/main/tweetAssignment/Bert_FineTuned.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFnhADsMUNtw"
      },
      "source": [
        "# This code was used for assignment 1 at the time of writing report.\r\n",
        "# Better score is obtained using Roberta retrained model, which is uploaded separately in github."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjO67vV6QU-P"
      },
      "source": [
        "#Need to install transfomers and nlp everytime the kernel restarts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EojGaw0sb_l"
      },
      "source": [
        "# run this cell, then restart the runtime before continuing\n",
        "!pip install nlp\n",
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjNExkIkQfh3"
      },
      "source": [
        "# Transformer apis runs efficiently only on GPUs, Adding a check, if GPU is unavailable, Raise System error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-LH9-hLgyoV"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "# Get the GPU device name.\r\n",
        "device_name = tf.test.gpu_device_name()\r\n",
        "# The device name should look like the following:\r\n",
        "if device_name == '/device:GPU:0':\r\n",
        "    print('Found GPU at: {}'.format(device_name))\r\n",
        "else:\r\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJS_L52Se00B"
      },
      "source": [
        "#Installing Necessities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXxZNuNCfIdv"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import random\r\n",
        "import requests\r\n",
        "\r\n",
        "import nltk\r\n",
        "from nltk import word_tokenize\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from nltk.classify import ClassifierI\r\n",
        "from nltk.stem import PorterStemmer\r\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from nltk.stem import WordNetLemmatizer\r\n",
        "import seaborn as sns\r\n",
        "\r\n",
        "from tqdm.notebook import tqdm\r\n",
        "\r\n",
        "from transformers import BertForSequenceClassification, BertTokenizer\r\n",
        "from transformers import AdamW,get_linear_schedule_with_warmup\r\n",
        "\r\n",
        "from sklearn.metrics import recall_score\r\n",
        "from sklearn.metrics import f1_score \r\n",
        "\r\n",
        "import torch\r\n",
        "from torch.utils.data import TensorDataset\r\n",
        "from torch.utils.data import RandomSampler,SequentialSampler,DataLoader\r\n",
        "\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings('ignore')\r\n",
        "\r\n",
        "nltk.download('stopwords')\r\n",
        "nltk.download('wordnet')\r\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuTogDJjQrH0"
      },
      "source": [
        "# Declaring URL link related to all the three datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32-g11zIKAqg"
      },
      "source": [
        "############################ SENTIMENT ANALYSIS #################################################\n",
        "SENTIMENT_TRAIN_TEXT = 'https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/sentiment/train_text.txt'\n",
        "SENTIMENT_VALIDATION_TEXT = 'https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/sentiment/val_text.txt'\n",
        "SENTIMENT_TEST_TEXT = 'https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/sentiment/test_text.txt'\n",
        "\n",
        "SENTIMENT_TRAIN_LABEL = 'https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/sentiment/train_labels.txt'\n",
        "SENTIMENT_VALIDATION_LABEL = 'https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/sentiment/val_labels.txt'\n",
        "SENTIMENT_TEST_LABEL = 'https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/sentiment/test_labels.txt'\n",
        "\n",
        "############################ HATE #################################################\n",
        "HATE_TRAIN_TEXT = 'https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/hate/train_text.txt'\n",
        "HATE_VALIDATION_TEXT = 'https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/hate/val_text.txt'\n",
        "HATE_TEST_TEXT = 'https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/hate/test_text.txt'\n",
        "\n",
        "HATE_TRAIN_LABEL = 'https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/hate/train_labels.txt'\n",
        "HATE_VALIDATION_LABEL = 'https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/hate/val_labels.txt'\n",
        "HATE_TEST_LABEL = 'https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/hate/test_labels.txt'\n",
        "\n",
        "############################ OFFENSIVE LANGUAGE#################################################\n",
        "OFFENSE_TRAIN_TEXT = 'https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/offensive/train_text.txt'\n",
        "OFFENSE_VALIDATION_TEXT = 'https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/offensive/val_text.txt'\n",
        "OFFENSE_TEST_TEXT = 'https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/offensive/test_text.txt'\n",
        "\n",
        "OFFENSE_TRAIN_LABEL = 'https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/offensive/train_labels.txt'\n",
        "OFFENSE_VALIDATION_LABEL = 'https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/offensive/val_labels.txt'\n",
        "OFFENSE_TEST_LABEL = 'https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/offensive/test_labels.txt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EevDzBIVQyvF"
      },
      "source": [
        "#In this part, text files are read from github, converted to pandsas dataframe and then processing is done to get rid of noise in the data. All the special characters are removed, words are lower-cased, lemmatization is done instead of stemming, all the words whose length is less than 2 are filtered, getting rid of 'user' from texts and calcualting the length of each tweet and storing it in dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utjMLdmqsUuA"
      },
      "source": [
        "def preprocess(df): \n",
        "    lemmatizer  = WordNetLemmatizer()\n",
        "    ignore_words = ['user', 'st'] \n",
        "    df['processed_tweets'] = df['tweet'].replace('[^a-zA-Z]',' ', regex=True,\n",
        "                                                  inplace=False)\n",
        "    df['processed_tweets'] = df['processed_tweets'].apply(lambda x: [w.lower() for w in x.split()])\n",
        "    # if classification_task == 'hate_analysis':\n",
        "    df['processed_tweets'] = df['processed_tweets'].apply(lambda tweet: ([word for word in tweet if not word in stopwords.words(\"english\")]))\n",
        "    df['processed_tweets'] = df['processed_tweets'].apply(lambda tweet: ([lemmatizer.lemmatize(word) for word in tweet]))\n",
        "\n",
        "    df['processed_tweets'] = df['processed_tweets'].apply(lambda tweet: ' '.join([word for word in tweet if len(word)>2]))\n",
        "\n",
        "    df['processed_tweets'] = df['processed_tweets'].apply(lambda x: ' '.join([word for word in x.split() if not word in ignore_words]))\n",
        "    \n",
        "    df[\"sentence_length\"] = df.tweet.apply(lambda x: len(str(x).split()))\n",
        "    return df\n",
        "\n",
        "\n",
        "# Wrapper to convert text data to pandas Dataframe\n",
        "def txt_to_df(data, label, classification_task):\n",
        "    tweet = []\n",
        "    sentiments = []\n",
        "    for sentence in data.split('\\n'):\n",
        "        tweet.append(sentence)\n",
        "    for sentiment in label.split('\\n'):\n",
        "        try:\n",
        "            sentiments.append(int(sentiment))\n",
        "        except ValueError:\n",
        "            pass\n",
        "    df= pd.DataFrame(tweet[:-1], columns=['tweet'])\n",
        "    df['label'] = sentiments\n",
        "    if classification_task == 'Sentiment_analysis':\n",
        "      df['sentiment'] = df.label.apply(lambda x: 'Negative'if x==0 else ('Neutral' if x==1 else 'Positive'))\n",
        "    if classification_task == 'hate_analysis':\n",
        "      df['sentiment'] = df.label.apply(lambda x: 'Not-hate'if x==0 else 'hate')\n",
        "    if classification_task == 'offensive_analysis':\n",
        "      df['sentiment'] = df.label.apply(lambda x: 'Not-offensive 'if x==0 else 'offensive')\n",
        "    return df\n",
        "\n",
        "\n",
        "def prepare_dataset(TRAIN_TEXT, TRAIN_LABEL, VAL_TEXT, VAL_LABEL, TEST_TEXT, TEST_LABEL, classification_task):\n",
        "  # Reading Train, Vvalidation & Test data from tweeteval Github Repo.\n",
        "  train_tweets_txt = requests.get(TRAIN_TEXT).text\n",
        "  train_labels_txt = requests.get(TRAIN_LABEL).text\n",
        "\n",
        "  val_tweets_txt = requests.get(VAL_TEXT).text\n",
        "  val_labels_txt = requests.get(VAL_LABEL).text\n",
        "\n",
        "  test_tweets_txt = requests.get(TEST_TEXT).text\n",
        "  test_labels_txt = requests.get(TEST_LABEL).text\n",
        "\n",
        "  # Converting text data to pandas Dataframe\n",
        "  train_df = txt_to_df(train_tweets_txt, train_labels_txt, classification_task)\n",
        "  val_df = txt_to_df(val_tweets_txt, val_labels_txt, classification_task)\n",
        "  test_df = txt_to_df(test_tweets_txt, test_labels_txt, classification_task)\n",
        "\n",
        "  train_df = preprocess(train_df)\n",
        "  val_df = preprocess(val_df)\n",
        "  test_df = preprocess(test_df)  \n",
        "\n",
        "  return train_df, val_df, test_df\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlhutJwlSK9O"
      },
      "source": [
        "# Initializing pretrained model of BertForSequenceClassification & BertTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAh5QlfnKAu4"
      },
      "source": [
        "def initialize_bert(num_of_class):\n",
        "  model = BertForSequenceClassification.from_pretrained('bert-base-uncased',\n",
        "                                      num_labels = num_of_class,\n",
        "                                      output_attentions = False,\n",
        "                                      output_hidden_states =  False)\n",
        "\n",
        "  tokenizer = BertTokenizer.from_pretrained('bert-base-uncased',\n",
        "                                          do_lower_case = True)\n",
        "  return model, tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evF0hKVRSVB3"
      },
      "source": [
        "# encode_data(tokenizer, df, max_sequence_length=256):\r\n",
        "Wrapper to perform encoding of data, this is called for train, validation and test dataset.\r\n",
        "\r\n",
        "# extract_inputId_attentionMask(df, encoder):\r\n",
        " Wrapper to Extract 'input_ids' and 'attention_mask' after encoding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZTLeMGZKAyO"
      },
      "source": [
        "def encode_data(tokenizer, df, max_sequence_length=256):\n",
        "  encoder = tokenizer.batch_encode_plus(df.tweet.values,\n",
        "                                            add_special_tokens = True,\n",
        "                                            pad_to_max_length = True,\n",
        "                                            #  max_length = 256,\n",
        "                                            max_length = max_sequence_length,\n",
        "                                            truncation=True,\n",
        "                                            return_tensors = 'pt')\n",
        "\n",
        "\n",
        "  return encoder\n",
        "\n",
        "def extract_inputId_attentionMask(df, encoder):\n",
        "  input_ids = encoder['input_ids']\n",
        "  attention_masks = encoder[\"attention_mask\"]\n",
        "  labels = torch.tensor(df.label.values)\n",
        "  return input_ids, attention_masks, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwtP6PEakOhL"
      },
      "source": [
        "# Wrappet that returns TensorDataset, created with input_ids, attenstion_masks and labels\r\n",
        "def get_tesnsor_dataset(input_ids, attention_masks, labels):\r\n",
        "  return TensorDataset(input_ids, attention_masks, labels)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4WxznU6TAwW"
      },
      "source": [
        "# Creating DataLoader object for all the datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdPST8kcnlz0"
      },
      "source": [
        "def dataloader_object(data, batch_size=16):\r\n",
        "  dataloader = DataLoader(\r\n",
        "    data,\r\n",
        "    sampler= RandomSampler(data),\r\n",
        "    batch_size = batch_size)\r\n",
        "  return dataloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIeDNPXITIRn"
      },
      "source": [
        "# Optional api for freezing bert layers for pretraining, we are not using it now. but will be considered later to increase the accuracy of prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrNuno0PpDlb"
      },
      "source": [
        "def freeze_bert_layers(model):\r\n",
        "  for param in model.bert.parameters():\r\n",
        "    param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRUxjXiWTTq-"
      },
      "source": [
        "# Displaying model parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BN5tZWYBjgQQ"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\r\n",
        "\r\n",
        "def print_model_params(model):\r\n",
        "  params = list(model.named_parameters())\r\n",
        "  print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\r\n",
        "  print('==== Embedding Layer ====\\n')\r\n",
        "  for p in params[0:5]:\r\n",
        "      print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\r\n",
        "  print('\\n==== First Transformer ====\\n')\r\n",
        "  for p in params[5:21]:\r\n",
        "      print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\r\n",
        "  print('\\n==== Output Layer ====\\n')\r\n",
        "  for p in params[-4:]:\r\n",
        "      print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uk2iUXfQTaLt"
      },
      "source": [
        "# For the purposes of fine-tuning, the authors recommend choosing from the following values:\r\n",
        "# Batch size: 16, 32 (We chose 32 when creating our DataLoaders).\r\n",
        "# Learning rate (Adam): 5e-5, 3e-5, 2e-5 (We’ll use 1e-5).\r\n",
        "# Number of epochs: 2, 3, 4 (We’ll use 1).\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfjkRczVKBCt"
      },
      "source": [
        "def initialize_optimizer(model, dataloader, lr=1e-5, epochs=2):\n",
        "  optimizer = AdamW(model.parameters(),lr,eps = 1e-8)\n",
        "\n",
        "  scheduler = get_linear_schedule_with_warmup(\n",
        "              optimizer,\n",
        "      num_warmup_steps = 0,\n",
        "    num_training_steps = len(dataloader)*epochs \n",
        "  )\n",
        "  return optimizer, scheduler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzPPGyjKTjKe"
      },
      "source": [
        "# F1 macro average score - needed for Hate and Offensive language analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwS3tPvfKBGH"
      },
      "source": [
        "def f1_score_func(predictions,y_labelled):\n",
        "    preds_flatten = np.argmax(predictions,axis=1).flatten()\n",
        "    labels_flatten = y_labelled.flatten()\n",
        "    return f1_score(labels_flatten,preds_flatten,average = 'macro')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKSkHqhOTtKs"
      },
      "source": [
        "# Recall macro average score - needed for Sentiment analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuxapDjIS9Ne"
      },
      "source": [
        "def recall_score_func(predictions,y_labelled):\r\n",
        "    preds_flatten = np.argmax(predictions,axis=1).flatten()\r\n",
        "    labels_flatten = y_labelled.flatten()\r\n",
        "    return recall_score(labels_flatten,preds_flatten,average = 'macro')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0krp1mA4T0u9"
      },
      "source": [
        "#Loading model to GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yh7k8RIrKBQS"
      },
      "source": [
        "def load_model_to_device(model):\n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "  model.to(device)\n",
        "  print(f\"Loading:{device}\")\n",
        "  return device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zqBJl3RUhbt"
      },
      "source": [
        "# Evaluation of model after every epoch on validation data set and on test dataset after training is completed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mqc7Vw9BKBTf"
      },
      "source": [
        "def evaluate(model, device, dataloader_val):\n",
        "    model.eval()\n",
        "    \n",
        "    loss_val_total = 0\n",
        "    predictions,true_vals = [],[]\n",
        "    \n",
        "    for batch in tqdm(dataloader_val):\n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        \n",
        "        inputs = {'input_ids':  batch[0],\n",
        "                  'attention_mask':batch[1],\n",
        "                  'labels': batch[2]\n",
        "                 }\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            \n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        loss_val_total +=loss.item()\n",
        "        \n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = inputs['labels'].cpu().numpy()\n",
        "        predictions.append(logits)\n",
        "        true_vals.append(label_ids)\n",
        "        \n",
        "        \n",
        "    loss_val_avg = loss_val_total/len(dataloader_val)  \n",
        "    \n",
        "    predictions = np.concatenate(predictions,axis=0)\n",
        "    true_vals = np.concatenate(true_vals,axis=0) \n",
        "    return loss_val_avg,predictions,true_vals"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MTVjmYKUrJQ"
      },
      "source": [
        "# Wrapper API to commence training and perform validation after every epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LO_4hnOIOpWL"
      },
      "source": [
        "def init_training(model, optimizer, scheduler, epochs, device, dataloader_train, dataloader_val): \n",
        "  for epoch in tqdm(range(1,epochs+1)):\n",
        "      model.train()\n",
        "      \n",
        "      loss_train_total=0\n",
        "      \n",
        "      progress_bar = tqdm(dataloader_train,desc = \"Epoch: {:1d}\".format(epoch),leave = False,disable = False)\n",
        "      \n",
        "      \n",
        "      for batch in progress_bar:\n",
        "          model.zero_grad()\n",
        "          \n",
        "          batch = tuple(b.to(device) for b in batch)\n",
        "          \n",
        "          inputs = {\n",
        "              \"input_ids\":batch[0],\n",
        "              \"attention_mask\":batch[1],\n",
        "              \"labels\":batch[2]\n",
        "              \n",
        "          }\n",
        "          outputs = model(**inputs)\n",
        "          \n",
        "          loss = outputs[0]\n",
        "          loss_train_total +=loss.item()\n",
        "          loss.backward()\n",
        "          \n",
        "          torch.nn.utils.clip_grad_norm(model.parameters(),1.0)\n",
        "          \n",
        "          optimizer.step()\n",
        "          scheduler.step()\n",
        "          \n",
        "          \n",
        "          progress_bar.set_postfix({'training_loss':'{:.3f}'.format(loss.item()/len(batch))})\n",
        "      \n",
        "      tqdm.write('\\nEpoch {epoch}')\n",
        "      \n",
        "      loss_train_avg = loss_train_total/len(dataloader_train)\n",
        "      tqdm.write(f'Training Loss: {loss_train_avg}')\n",
        "      val_loss,predictions,true_vals = evaluate(model,device, dataloader_val)\n",
        "\n",
        "# As per TweetEval, using recall as evaluation metric only for sentiment analysis.\n",
        "      if classification_task == 'SENTIMENT_ANALYSIS':\n",
        "        test_score = recall_score_func(predictions,true_vals)\n",
        "      else:\n",
        "        test_score = f1_score_func(predictions,true_vals)\n",
        "      \n",
        "\n",
        "      tqdm.write(f'Val Loss:{val_loss}\\n Test Score:{test_score}')\n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q17sYfbmOpfD"
      },
      "source": [
        "def evaluate_wrapper(model, device, dataloader_test):\n",
        "  val_loss,predictions,true_vals = evaluate(model,device, dataloader_test)\n",
        "\n",
        "  if classification_task == 'SENTIMENT_ANALYSIS':\n",
        "    test_score = recall_score_func(predictions,true_vals)\n",
        "  else:\n",
        "    test_score = f1_score_func(predictions,true_vals)  \n",
        "\n",
        "  tqdm.write(f'Val Loss:{val_loss}\\n Test Score:{test_score}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXxoK6lcVJ-2"
      },
      "source": [
        "# All the APIs needed for fine tuning bert model is called from this wrapper."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGYy-c76KA1T"
      },
      "source": [
        "def fineTune_bert(batch_size, lr, epochs, max_length):\n",
        "\n",
        "  num_of_class= len(train_df.sentiment.unique())\n",
        "\n",
        "  seed_val = 17\n",
        "  random.seed(seed_val)\n",
        "  np.random.seed(seed_val)\n",
        "  torch.manual_seed(seed_val)\n",
        "  torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "\n",
        "  model, tokenizer = initialize_bert(num_of_class)\n",
        "\n",
        "  encoder_train = encode_data(tokenizer, train_df, max_length)\n",
        "  encoder_eval = encode_data(tokenizer, val_df, max_length)\n",
        "  encoder_test = encode_data(tokenizer, test_df, max_length)\n",
        "\n",
        "  input_ids_train, attention_masks_train, labels_train = extract_inputId_attentionMask(train_df, encoder_train)\n",
        "  input_ids_eval, attention_masks_eval, labels_eval = extract_inputId_attentionMask(val_df, encoder_eval)\n",
        "  input_ids_test, attention_masks_test, labels_test = extract_inputId_attentionMask(test_df, encoder_test)\n",
        "\n",
        "  data_train = get_tesnsor_dataset(input_ids_train,attention_masks_train,labels_train)\n",
        "  data_eval = get_tesnsor_dataset(input_ids_eval,attention_masks_eval,labels_eval)\n",
        "  data_test = get_tesnsor_dataset(input_ids_test,attention_masks_test,labels_test)\n",
        "\n",
        "  dataloader_train = dataloader_object(data_train, batch_size) \n",
        "  dataloader_eval = dataloader_object(data_eval, batch_size) \n",
        "  dataloader_test = dataloader_object(data_test, batch_size)\n",
        "\n",
        "  # freeze_bert_layers(model)\n",
        "  print_model_params(model)\n",
        "  optimizer, scheduler = initialize_optimizer(model,dataloader_train, lr, epochs)\n",
        "  device = load_model_to_device(model)\n",
        "\n",
        "  init_training(model,optimizer,  scheduler, epochs, device, dataloader_train, dataloader_test)\n",
        "  evaluate_wrapper(model, device, dataloader_eval)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QkRqHB4xA_V"
      },
      "source": [
        "For the purposes of fine-tuning, the authors recommend choosing from the following values:\r\n",
        "Batch size: 16, 32 (We chose 16 when creating our DataLoaders)\r\n",
        "  \r\n",
        "\r\n",
        "For the purposes of fine-tuning, the authors recommend choosing from the following values:\r\n",
        "Batch size: 16, 32 (We chose 32 when creating our DataLoaders).\r\n",
        "Learning rate (Adam): 5e-5, 3e-5, 2e-5 (We’ll use 1e-5).\r\n",
        "Number of epochs: 2, 3, 4 (We’ll use 4)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ub3o88XtVtiO"
      },
      "source": [
        "score 71.28 --- 70.02\r\n",
        "batch size train-16, val 32, test -32\r\n",
        "lr = 1e-5\r\n",
        "1 Epoch\r\n",
        "max_length = 256\r\n",
        "score 71.19(epoch-1)\r\n",
        "batch size train-16, val 16, test -16\r\n",
        "lr = 1e-5\r\n",
        "1 Epoch\r\n",
        "max_length = 125\r\n",
        "score (epoch-1)\r\n",
        "batch size train-16, val 16, test -16\r\n",
        "lr = 2e-5\r\n",
        "1 Epoch\r\n",
        "max_length = 125"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSuaT8EXVVZX"
      },
      "source": [
        "# Training and evaluation for all the three tasks is done in a loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LE3hl_IQf-Li"
      },
      "source": [
        "classification_task_dict = {'SENTIMENT_ANALYSIS' : 'Sentiment_analysis',\r\n",
        "                      'HATE_ANALYSIS' : 'hate_analysis',\r\n",
        "                      'OFFENSIVE_LANGUAGE' : 'offensive_analysis'\r\n",
        "                      }\r\n",
        "class_dict = {'SENTIMENT_ANALYSIS' :['Negative', 'Neutral', 'Positive'],\r\n",
        "              'HATE_ANALYSIS' : ['Not-hate', 'hate'],\r\n",
        "              'OFFENSIVE_LANGUAGE' : ['Not-offensive', 'offensive']}\r\n",
        "\r\n",
        "config = {'batch_size' : 16,\r\n",
        "          'lr' : 1e-5,\r\n",
        "          'epochs' : 1,\r\n",
        "          'max_length' : 256\r\n",
        "        }\r\n",
        "\r\n",
        "#         score 71.28 --- 70.02\r\n",
        "# batch size train-16, val 32, test -32\r\n",
        "# lr = 1e-5\r\n",
        "# 1 Epoch\r\n",
        "# max_length = 256\r\n",
        "\r\n",
        "for classification_task, task in classification_task_dict.items():\r\n",
        "  print('=========================================')\r\n",
        "  print('CLASSIFICATION TASK: {}'.format(classification_task))\r\n",
        "  print('=========================================')\r\n",
        "  if classification_task == 'SENTIMENT_ANALYSIS':\r\n",
        "    # continue\r\n",
        "    train_df, val_df, test_df = prepare_dataset(SENTIMENT_TRAIN_TEXT, SENTIMENT_TRAIN_LABEL,\r\n",
        "                        SENTIMENT_VALIDATION_TEXT, SENTIMENT_VALIDATION_LABEL,\r\n",
        "                        SENTIMENT_TEST_TEXT, SENTIMENT_TEST_LABEL, classification_task_dict['SENTIMENT_ANALYSIS']\r\n",
        "                        )\r\n",
        "\r\n",
        "  if classification_task == 'HATE_ANALYSIS':\r\n",
        "    # continue\r\n",
        "    train_df, val_df, test_df = prepare_dataset(HATE_TRAIN_TEXT, HATE_TRAIN_LABEL,\r\n",
        "                        HATE_VALIDATION_TEXT, HATE_VALIDATION_LABEL,\r\n",
        "                        HATE_TEST_TEXT, HATE_TEST_LABEL, classification_task_dict['HATE_ANALYSIS']\r\n",
        "                        )\r\n",
        "    \r\n",
        "  if classification_task == 'OFFENSIVE_LANGUAGE':\r\n",
        "    # continue\r\n",
        "    train_df, val_df, test_df = prepare_dataset(OFFENSE_TRAIN_TEXT, OFFENSE_TRAIN_LABEL,\r\n",
        "                        OFFENSE_VALIDATION_TEXT, OFFENSE_VALIDATION_LABEL,\r\n",
        "                        OFFENSE_TEST_TEXT, OFFENSE_TEST_LABEL, classification_task_dict['OFFENSIVE_LANGUAGE']\r\n",
        "                        )\r\n",
        "  fineTune_bert(config['batch_size'], config['lr'], config['epochs'], config['max_length'])\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}